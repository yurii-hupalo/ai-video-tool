import streamlit as st
import fal_client
import openai
import os
import requests
import json
import subprocess

# –°–ø—Ä–æ–±–∞ —ñ–º–ø–æ—Ä—Ç—É mutagen
try:
    from mutagen.mp3 import MP3
except ImportError:
    st.error("üö® –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ `mutagen` –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –í–≤–µ–¥–∏: pip install mutagen")
    MP3 = None

# --- –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø ---
st.set_page_config(page_title="AI Mega Studio", page_icon="üéõÔ∏è", layout="wide")

# ==========================================
# 1. –°–ò–°–¢–ï–ú–ù–Ü –§–£–ù–ö–¶–Ü–á
# ==========================================

def check_ffmpeg():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except FileNotFoundError:
        return False

def save_file(url, filename):
    try:
        r = requests.get(url)
        with open(filename, 'wb') as f: f.write(r.content)
        return filename
    except Exception as e:
        st.error(f"Save Error: {e}")
        return None

def get_audio_duration(filename):
    if MP3 is None: return 5
    try:
        audio = MP3(filename)
        return audio.info.length
    except Exception:
        return 5

# --- –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ê–£–î–Ü–û ---
def generate_voiceover(text, voice_name, filename):
    try:
        client = openai.OpenAI()
        response = client.audio.speech.create(
            model="tts-1",
            voice=voice_name,
            input=text
        )
        response.stream_to_file(filename)
        return filename
    except Exception as e:
        st.error(f"TTS Error: {e}")
        return None

def generate_subtitles(audio_path):
    try:
        client = openai.OpenAI()
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1", file=audio_file, response_format="srt"
            )
        srt_filename = "subtitles.srt"
        with open(srt_filename, "w") as f:
            f.write(transcript)
        return os.path.abspath(srt_filename)
    except Exception as e:
        st.warning(f"Subs Error: {e}")
        return None

# --- –û–ë–†–û–ë–ö–ê –í–Ü–î–ï–û ---

def normalize_visual(input_path, output_path, duration, width, height):
    input_abs = os.path.abspath(input_path)
    output_abs = os.path.abspath(output_path)
    scale = f"scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,setsar=1"
    
    if input_path.endswith(".jpg") or input_path.endswith(".png"):
        cmd = [
            "ffmpeg", "-y", "-loop", "1", "-i", input_abs,
            "-vf", f"{scale},format=yuv420p",
            "-c:v", "libx264", "-t", str(duration), "-pix_fmt", "yuv420p", "-r", "25",
            output_abs
        ]
    else:
        cmd = [
            "ffmpeg", "-y", "-i", input_abs,
            "-vf", f"{scale},fps=25,format=yuv420p",
            "-c:v", "libx264", "-t", str(duration), "-pix_fmt", "yuv420p",
            output_abs
        ]
    subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return output_abs

def assemble_final_video(clips, music_path, voice_path, sub_path, output_path):
    list_file = os.path.abspath("clips.txt")
    with open(list_file, "w") as f:
        for clip in clips:
            f.write(f"file '{clip}'\n")
    
    abs_music = os.path.abspath(music_path)
    abs_voice = os.path.abspath(voice_path) if voice_path else None
    
    cmd = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_file]
    cmd += ["-stream_loop", "-1", "-i", abs_music]
    
    filter_complex = ""
    if abs_voice:
        cmd += ["-i", abs_voice]
        filter_complex = "[1:a]volume=0.1[bg];[2:a]volume=1.3[speech];[bg][speech]amix=inputs=2:duration=first[a_out]"
    else:
        filter_complex = "[1:a]volume=1.0[a_out]"

    video_filter = "null"
    if sub_path:
        sub_escaped = sub_path.replace("\\", "/").replace(":", "\\:")
        video_filter = f"subtitles='{sub_escaped}':force_style='Fontsize=18,PrimaryColour=&Hffffff,OutlineColour=&H000000,BorderStyle=1,Outline=1,Shadow=0,Alignment=2,MarginV=50'"

    cmd += [
        "-filter_complex", f"{filter_complex};[0:v]{video_filter}[v_out]",
        "-map", "[v_out]", "-map", "[a_out]",
        "-c:v", "libx264", "-c:a", "aac", "-b:a", "192k", "-shortest",
        output_path
    ]
    
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return output_path
    except subprocess.CalledProcessError as e:
        st.error(f"FFmpeg Error: {e}")
        return None

# ==========================================
# 2. –Ü–ù–¢–ï–†–§–ï–ô–° (SIDEBAR)
# ==========================================
with st.sidebar:
    st.title("üéõÔ∏è AI Mega Studio")
    
    openai_key = st.text_input("OpenAI Key", type="password", value="[–ê–ü–Ü –ö–õ–Æ–ß –û–ü–ï–ù–ê–Ü]")
    fal_key = st.text_input("Fal.ai Key", type="password", value="[–ê–ü–Ü –ö–õ–Æ–ß –§–ê–õ –ê–Ü]")
    
    st.markdown("---")
    
    # –ó–ú–Ü–ù–ï–ù–û –ü–û–†–Ø–î–û–ö: Story Mode —Ç–µ–ø–µ—Ä –ø–µ—Ä—à–∏–π (–¥–µ—Ñ–æ–ª—Ç–Ω–∏–π)
    MODE = st.selectbox("–û–±–µ—Ä–∏ —Ä–µ–∂–∏–º:", [
        "üìú Story Mode (Slideshow)", 
        "üöÄ Hybrid Pro (Video+Img+Subs)",
        "üé¨ Quick Loop (Kling)"
    ])
    
    st.markdown("---")
    format_opt = st.radio("–§–æ—Ä–º–∞—Ç:", ("9:16 (TikTok)", "16:9 (YouTube)"))
    if "9:16" in format_opt:
        W, H = 720, 1280
        fal_size = "portrait_16_9"
    else:
        W, H = 1280, 720
        fal_size = "landscape_16_9"
        
    st.markdown("### üéµ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
    voice_opt = st.selectbox("–ì–æ–ª–æ—Å:", ["onyx", "alloy", "echo", "shimmer", "nova", "fable"])
    uploaded_music = st.file_uploader("–§–æ–Ω–æ–≤–∞ –º—É–∑–∏–∫–∞ (mp3)", type=["mp3"])
    add_subs = st.checkbox("–î–æ–¥–∞—Ç–∏ —Å—É–±—Ç–∏—Ç—Ä–∏", value=True)
    
    # --- –í–ò–ü–†–ê–í–õ–ï–ù–û: –°–ª–∞–π–¥–µ—Ä —Ç–µ–ø–µ—Ä –∑–∞–≤–∂–¥–∏ —Ç—É—Ç ---
    st.markdown("### üìù –ö—ñ–ª—å–∫—ñ—Å—Ç—å –°—Ü–µ–Ω")
    num_scenes = st.slider("–û–±–µ—Ä–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å:", 1, 20, 5)
    
    if MODE == "üé¨ Quick Loop (Kling)":
        st.info("‚ÑπÔ∏è –î–ª—è Quick Loop –±—É–¥–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∞ –ª–∏—à–µ 1 —Å—Ü–µ–Ω–∞, –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–ª–∞–π–¥–µ—Ä–∞.")
        real_num_scenes = 1
    else:
        real_num_scenes = num_scenes

# ==========================================
# 3. –õ–û–ì–Ü–ö–ê –ü–†–û–ì–†–ê–ú–ò
# ==========================================

st.title(f"{MODE}")

if not check_ffmpeg():
    st.error("üö® –ù–µ–º–∞—î FFmpeg!")
    st.stop()
    
if "[–ê–ü–Ü" in openai_key:
    st.warning("–í—Å—Ç–∞–≤ –∫–ª—é—á—ñ!")
    st.stop()

os.environ["OPENAI_API_KEY"] = openai_key
os.environ["FAL_KEY"] = fal_key

topic = st.text_input("–¢–µ–º–∞ —Ç–≤–æ–≥–æ –≤—ñ–¥–µ–æ:", "The history of coffee")

if st.button("üöÄ –ü–û–ß–ê–¢–ò –ì–ï–ù–ï–†–ê–¶–Ü–Æ"):
    
    with st.status("üèóÔ∏è –ü—Ä–∞—Ü—é—é...", expanded=True) as status:
        
        # --- –ï–¢–ê–ü 1: –°–¶–ï–ù–ê–†–Ü–ô ---
        st.write("üìù 1. –°—Ü–µ–Ω–∞—Ä—ñ–π...")
        client = openai.OpenAI()
        
        if MODE == "üé¨ Quick Loop (Kling)":
            prompt = f"Create a looping video concept for '{topic}'. JSON: {{'visual_prompt': 'desc', 'music_mood': 'desc'}}"
        
        elif MODE == "üìú Story Mode (Slideshow)":
            prompt = f"Create a documentary script for '{topic}' with {real_num_scenes} scenes. JSON: {{'scenes': ['img1', 'img2'...], 'narration': 'text', 'music_mood': 'desc'}}"
            
        elif MODE == "üöÄ Hybrid Pro (Video+Img+Subs)":
            prompt = f"""
            Create a hybrid video script for '{topic}' with {real_num_scenes} scenes. 
            Use 'video' type only for high action, 'image' for static.
            JSON: {{
                "narration": "text", 
                "music_mood": "desc",
                "scenes": [
                    {{'type': 'image', 'prompt': '... '}},
                    {{'type': 'video', 'prompt': '... '}}
                ]
            }}
            """
            
        resp = client.chat.completions.create(model="gpt-4o", messages=[{"role":"user", "content": prompt}], response_format={"type": "json_object"})
        data = json.loads(resp.choices[0].message.content)
        
        # --- –ï–¢–ê–ü 2: –ê–£–î–Ü–û ---
        st.write("üéôÔ∏è 2. –ê—É–¥—ñ–æ...")
        voice_path = None
        voice_dur = 5
        if 'narration' in data:
            voice_path = generate_voiceover(data['narration'], voice_opt, "voice.mp3")
            voice_dur = get_audio_duration(voice_path)
        
        music_path = "music.mp3"
        if uploaded_music:
            with open(music_path, "wb") as f: f.write(uploaded_music.getbuffer())
        else:
            music_len = 15 if MODE == "üé¨ Quick Loop (Kling)" else min(int(voice_dur + 5), 45)
            try:
                h_mus = fal_client.submit("fal-ai/stable-audio", arguments={"prompt": data['music_mood'], "seconds_total": music_len})
                save_file(h_mus.get()['audio_file']['url'], music_path)
            except:
                st.warning("–ú—É–∑–∏–∫–∞ –Ω–µ –≤–∏–π—à–ª–∞.")

        sub_path = None
        if add_subs and voice_path:
            st.write("üìù –°—É–±—Ç–∏—Ç—Ä–∏...")
            sub_path = generate_subtitles(voice_path)

        # --- –ï–¢–ê–ü 3: –í–Ü–ó–£–ê–õ ---
        st.write(f"üé® 3. –í—ñ–∑—É–∞–ª ({real_num_scenes} —Å—Ü–µ–Ω)...")
        clips = []
        
        if MODE == "üé¨ Quick Loop (Kling)":
            h_img = fal_client.submit("fal-ai/flux-pro", arguments={"prompt": data['visual_prompt'], "image_size": fal_size})
            img_url = h_img.get()['images'][0]['url']
            h_vid = fal_client.submit("fal-ai/kling-video/v1/standard/image-to-video", arguments={"prompt": data['visual_prompt'], "image_url": img_url, "duration": "5"})
            vid_path = save_file(h_vid.get()['video']['url'], "raw_kling.mp4")
            clips.append(normalize_visual(vid_path, "clip_0.mp4", 10, W, H))
            
        elif MODE == "üìú Story Mode (Slideshow)":
            time_per_slide = voice_dur / len(data['scenes'])
            prog = st.progress(0)
            for i, p in enumerate(data['scenes']):
                try:
                    h = fal_client.submit("fal-ai/recraft-v3", arguments={"prompt": p, "image_size": fal_size, "style": "realistic_image"})
                    img_path = save_file(h.get()['images'][0]['url'], f"raw_{i}.jpg")
                    clips.append(normalize_visual(img_path, f"clip_{i}.mp4", time_per_slide, W, H))
                    prog.progress((i+1)/len(data['scenes']))
                except Exception as e:
                    st.warning(f"Error scene {i}: {e}")
                
        elif MODE == "üöÄ Hybrid Pro (Video+Img+Subs)":
            time_per_scene = voice_dur / len(data['scenes'])
            prog = st.progress(0)
            for i, scene in enumerate(data['scenes']):
                prompt = scene['prompt']
                try:
                    if scene['type'] == 'video':
                        h_img = fal_client.submit("fal-ai/flux-pro", arguments={"prompt": prompt, "image_size": fal_size})
                        img_url = h_img.get()['images'][0]['url']
                        h_vid = fal_client.submit("fal-ai/kling-video/v1/standard/image-to-video", arguments={"prompt": prompt, "image_url": img_url, "duration": "5"})
                        raw = save_file(h_vid.get()['video']['url'], f"raw_{i}.mp4")
                    else:
                        h_img = fal_client.submit("fal-ai/recraft-v3", arguments={"prompt": prompt, "image_size": fal_size, "style": "realistic_image"})
                        raw = save_file(h_img.get()['images'][0]['url'], f"raw_{i}.jpg")
                    
                    clips.append(normalize_visual(raw, f"clip_{i}.mp4", time_per_scene, W, H))
                    prog.progress((i+1)/len(data['scenes']))
                except Exception as e:
                    st.warning(f"Error scene {i}: {e}")

        # --- –ï–¢–ê–ü 4: –ú–û–ù–¢–ê–ñ ---
        st.write("üé¨ 4. –§—ñ–Ω–∞–ª—å–Ω–∞ –∑–±—ñ—Ä–∫–∞...")
        final_file = "RESULT.mp4"
        res = assemble_final_video(clips, music_path, voice_path, sub_path, final_file)
        
        status.update(label="‚úÖ –ì–û–¢–û–í–û!", state="complete")

    if res:
        st.balloons()
        st.success(f"–†–µ–∂–∏–º: {MODE} | –§–æ—Ä–º–∞—Ç: {format_opt}")
        st.video(res)
        with open(res, "rb") as f:
            st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç–∏", f, "ai_result.mp4")